{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93938004",
   "metadata": {},
   "source": [
    "# MVP: Machine Learning & Analytics\n",
    "\n",
    "**Autor**: Rodrigo Eduardo Modesto de Abreu\n",
    "\n",
    "**Data**: 27/08/2025\n",
    "\n",
    "**Matrícula**: 4052025000009\n",
    "\n",
    "**Dataset**: [Diamond Prices](https://www.kaggle.com/datasets/nancyalaswad90/diamonds-prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6249e1f",
   "metadata": {},
   "source": [
    "Introduction\n",
    "\n",
    "The MVP is based on the Diamond Prices dataset which was also used as part of the development of the [MVP2](https://github.com/remabreu/DiamondsPrices/tree/main).\n",
    "\n",
    "At this repository, you can find:\n",
    "* [README file](https://github.com/remabreu/DiamondsPrices/blob/main/README.md) - That describes details of the dataset\n",
    "* [Notebook](https://github.com/remabreu/DiamondsPrices/blob/main/diamonds.ipynb) - The Notebook includes the whole dataset analysis and preporcessing which is also replicated in the notebook.\n",
    "\n",
    "The Problem\n",
    "\n",
    "The Diamonds Prices dataset provides many features to support in the prediction of the target variable as a supervised regression learning. The  dataset is a common and well known regression problem in [Kaggle](https://www.kaggle.com/datasets/nancyalaswad90/diamonds-prices). The Dataset is in the latest updated version and contains 53943 records and 11 Features (one of the attributes is the index and has no relationship with the data analysis).\n",
    "\n",
    "Exploratory Data Analysis\n",
    "\n",
    "In summary, the dataseset present as the following:\n",
    "* The dataset didn't present any missing data (only )\n",
    "* Prices column was very unbalanced and skewed distribution. \n",
    "* The uncommon prices can be regarded either outliers or not depending on how will be the use of the Diamonds for example, a value maximizer (i.e. Industrial use), collector or bridal budget. In fact there it hasn't been observed any miss-measurement or error to also regard any outlier. However, these measurements the extrapolate the \"fence\" outside the Quartile 1 and 2 through IQR method.\n",
    "* carat and price produced a strong correlation in which cut, color and clarity were adjectives of such correlation by contributing into superior prices for the same carat. This behavior was more distinctly observed on smaller/lighter carats, though."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb2e1dc",
   "metadata": {},
   "source": [
    "Data Preprocessing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e586f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not show warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Imports \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random # to define random seed\n",
    "\n",
    "import kagglehub\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "# Model Selection\n",
    "from sklearn.model_selection import train_test_split # partition the dataset into train and test (holdout)\n",
    "from sklearn.model_selection import KFold # preprare the folds to cross validation \n",
    "from sklearn.model_selection import cross_val_score # execuite cross validation\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import mean_squared_error # MSE Evaluation Metric\n",
    "from sklearn.metrics import mean_absolute_error # MAE evaluiation metric\n",
    "from sklearn.metrics import r2_score # R² evaluation metric\n",
    "\n",
    "# Algorithms\n",
    "from sklearn.linear_model import LinearRegression # Linear Regression algorithm \n",
    "from sklearn.linear_model import Ridge # Ridge Regularization algorithm\n",
    "from sklearn.linear_model import Lasso # Lasso Regularization algorithm\n",
    "from sklearn.neighbors import KNeighborsRegressor # KNN algorithm\n",
    "from sklearn.tree import DecisionTreeRegressor # Decision Tree algorithm\n",
    "from sklearn.dummy import DummyRegressor # Baseline algorithm\n",
    "from sklearn.ensemble import RandomForestRegressor # Random Forest algorithm\n",
    "from sklearn.svm import SVR # algoritmo SVM\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "c28418d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.13)\n",
      "Path to dataset file: C:\\Users\\rodri\\.cache\\kagglehub\\datasets\\nancyalaswad90\\diamonds-prices\\versions\\4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1388</th>\n",
       "      <td>1389</td>\n",
       "      <td>0.24</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>G</td>\n",
       "      <td>VVS1</td>\n",
       "      <td>62.10</td>\n",
       "      <td>56.00</td>\n",
       "      <td>559</td>\n",
       "      <td>3.97</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19841</th>\n",
       "      <td>19842</td>\n",
       "      <td>1.21</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>F</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.90</td>\n",
       "      <td>54.00</td>\n",
       "      <td>8403</td>\n",
       "      <td>6.78</td>\n",
       "      <td>6.82</td>\n",
       "      <td>4.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41647</th>\n",
       "      <td>41648</td>\n",
       "      <td>0.50</td>\n",
       "      <td>Fair</td>\n",
       "      <td>E</td>\n",
       "      <td>SI1</td>\n",
       "      <td>61.70</td>\n",
       "      <td>68.00</td>\n",
       "      <td>1238</td>\n",
       "      <td>5.09</td>\n",
       "      <td>5.03</td>\n",
       "      <td>3.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41741</th>\n",
       "      <td>41742</td>\n",
       "      <td>0.50</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>D</td>\n",
       "      <td>SI2</td>\n",
       "      <td>62.80</td>\n",
       "      <td>56.00</td>\n",
       "      <td>1243</td>\n",
       "      <td>5.06</td>\n",
       "      <td>5.03</td>\n",
       "      <td>3.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17244</th>\n",
       "      <td>17245</td>\n",
       "      <td>1.55</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>E</td>\n",
       "      <td>SI2</td>\n",
       "      <td>62.30</td>\n",
       "      <td>55.00</td>\n",
       "      <td>6901</td>\n",
       "      <td>7.44</td>\n",
       "      <td>7.37</td>\n",
       "      <td>4.61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  carat        cut color clarity  depth  table  price    x  \\\n",
       "1388         1389   0.24      Ideal     G    VVS1  62.10  56.00    559 3.97   \n",
       "19841       19842   1.21  Very Good     F     VS2  62.90  54.00   8403 6.78   \n",
       "41647       41648   0.50       Fair     E     SI1  61.70  68.00   1238 5.09   \n",
       "41741       41742   0.50      Ideal     D     SI2  62.80  56.00   1243 5.06   \n",
       "17244       17245   1.55      Ideal     E     SI2  62.30  55.00   6901 7.44   \n",
       "\n",
       "         y    z  \n",
       "1388  4.00 2.47  \n",
       "19841 6.82 4.28  \n",
       "41647 5.03 3.12  \n",
       "41741 5.03 3.17  \n",
       "17244 7.37 4.61  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = kagglehub.dataset_download(\"nancyalaswad90/diamonds-prices\")\n",
    "\n",
    "print(\"Path to dataset file:\", path)\n",
    "\n",
    "#Store the dataset into a Dataframe object\n",
    "diamonds_df = pd.read_csv(path+\"/Diamonds Prices2022.csv\")\n",
    "df_sample = diamonds_df.sample(frac=0.2, random_state=42)\n",
    "\n",
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "279420fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10,789.00</td>\n",
       "      <td>10789</td>\n",
       "      <td>10789</td>\n",
       "      <td>10789</td>\n",
       "      <td>10,789.00</td>\n",
       "      <td>10,789.00</td>\n",
       "      <td>10,789.00</td>\n",
       "      <td>10,789.00</td>\n",
       "      <td>10,789.00</td>\n",
       "      <td>10,789.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>G</td>\n",
       "      <td>SI1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4316</td>\n",
       "      <td>2299</td>\n",
       "      <td>2521</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.79</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.77</td>\n",
       "      <td>57.45</td>\n",
       "      <td>3,876.57</td>\n",
       "      <td>5.72</td>\n",
       "      <td>5.72</td>\n",
       "      <td>3.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.45</td>\n",
       "      <td>2.26</td>\n",
       "      <td>3,951.53</td>\n",
       "      <td>1.12</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.00</td>\n",
       "      <td>51.00</td>\n",
       "      <td>335.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.10</td>\n",
       "      <td>56.00</td>\n",
       "      <td>944.00</td>\n",
       "      <td>4.71</td>\n",
       "      <td>4.72</td>\n",
       "      <td>2.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.90</td>\n",
       "      <td>57.00</td>\n",
       "      <td>2,388.00</td>\n",
       "      <td>5.69</td>\n",
       "      <td>5.71</td>\n",
       "      <td>3.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62.60</td>\n",
       "      <td>59.00</td>\n",
       "      <td>5,195.00</td>\n",
       "      <td>6.52</td>\n",
       "      <td>6.52</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78.20</td>\n",
       "      <td>95.00</td>\n",
       "      <td>18,803.00</td>\n",
       "      <td>10.74</td>\n",
       "      <td>10.54</td>\n",
       "      <td>31.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           carat    cut  color clarity     depth     table     price  \\\n",
       "count  10,789.00  10789  10789   10789 10,789.00 10,789.00 10,789.00   \n",
       "unique       NaN      5      7       8       NaN       NaN       NaN   \n",
       "top          NaN  Ideal      G     SI1       NaN       NaN       NaN   \n",
       "freq         NaN   4316   2299    2521       NaN       NaN       NaN   \n",
       "mean        0.79    NaN    NaN     NaN     61.77     57.45  3,876.57   \n",
       "std         0.47    NaN    NaN     NaN      1.45      2.26  3,951.53   \n",
       "min         0.20    NaN    NaN     NaN     43.00     51.00    335.00   \n",
       "25%         0.40    NaN    NaN     NaN     61.10     56.00    944.00   \n",
       "50%         0.70    NaN    NaN     NaN     61.90     57.00  2,388.00   \n",
       "75%         1.04    NaN    NaN     NaN     62.60     59.00  5,195.00   \n",
       "max         5.01    NaN    NaN     NaN     78.20     95.00 18,803.00   \n",
       "\n",
       "               x         y         z  \n",
       "count  10,789.00 10,789.00 10,789.00  \n",
       "unique       NaN       NaN       NaN  \n",
       "top          NaN       NaN       NaN  \n",
       "freq         NaN       NaN       NaN  \n",
       "mean        5.72      5.72      3.54  \n",
       "std         1.12      1.11      0.74  \n",
       "min         0.00      0.00      0.00  \n",
       "25%         4.71      4.72      2.91  \n",
       "50%         5.69      5.71      3.52  \n",
       "75%         6.52      6.52      4.03  \n",
       "max        10.74     10.54     31.80  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop first column, ignore error in case culumn doesn't exist (already removed)\n",
    "df_sample = df_sample.drop('Unnamed: 0', axis=1, errors='ignore')\n",
    "df_sample.describe(include='all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "c795d271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with 0 or empty values:  4\n",
      "Removing rows with 0 or empty values\n",
      "Rows with 0 or empty values:  0\n"
     ]
    }
   ],
   "source": [
    "# Check for 0 or empty values in 'x', 'y', 'z' columns\n",
    "#\n",
    "print(\"Rows with 0 or empty values: \", ((df_sample['x'] == 0) | (df_sample['y'] == 0) | (df_sample['z'] == 0)).sum())\n",
    "print(\"Removing rows with 0 or empty values\")\n",
    "df_sample = df_sample[(df_sample['x'] != 0) & (df_sample['y'] != 0) & (df_sample['z'] != 0)]\n",
    "print(\"Rows with 0 or empty values: \", ((df_sample['x'] == 0) | (df_sample['y'] == 0) | (df_sample['z'] == 0)).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e866b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_df = diamonds_df.drop(['x', 'y', 'z'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "88244b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Separate features and target\n",
    "X = df_sample.drop(columns='price')\n",
    "y = df_sample['price']\n",
    "\n",
    "# Step 2: Apply transformation to y\n",
    "y_log = np.log1p(y)\n",
    "y_log = y_log.to_frame()\n",
    "\n",
    "# Step 3: Train/test split\n",
    "# test_size: represents the proportion of the dataset to be allocated to the test set\n",
    "# random_state: get the same split of data every time the code is executed\n",
    "X_train, X_test, y_train_log, y_test_log = train_test_split(X, y_log,\n",
    "                                                            train_size=0.2,\n",
    "                                                            #test_size=0.2,\n",
    "                                                            random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "83f78bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iqr_filter(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "\n",
    "# Apply IQR filtering on training set only\n",
    "# merge sets (X) and (y) to apply filter\n",
    "train = X_train.copy()\n",
    "train['price'] = y_train_log\n",
    "train = iqr_filter(train, 'table')\n",
    "train = iqr_filter(train, 'depth')\n",
    "\n",
    "# Separate back\n",
    "y_train_log = train['price']\n",
    "X_train = train.drop(columns='price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "d12e311e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_num_cols = ['carat', 'table', 'depth', 'x', 'y', 'z']\n",
    "X_cat_cols = ['cut', 'color', 'clarity']\n",
    "y_num_col = ['price']\n",
    "\n",
    "# The ColumnTransformer creates a data preprocessing pipeline that applies\n",
    "# different transformations to different columns\n",
    "preprocessor_X = ColumnTransformer(\n",
    "    # List of transformations to be applied to specific column groups\n",
    "    transformers=[\n",
    "        # 1st Transformer: Numerical columns\n",
    "        ('t_num',\n",
    "         StandardScaler(), # Applies standardization (mean=0, std=1)\n",
    "         X_num_cols),\n",
    "\n",
    "        # 2nd Transformer: Categorical columns\n",
    "        ('t_cat',\n",
    "         # Converts categories to one-hot encoded columns and\n",
    "         #drops first category to avoid multicollinearity\n",
    "         OneHotEncoder(drop='first', sparse_output=False),\n",
    "         X_cat_cols)\n",
    "    ],\n",
    "    # Handling of columns not explicitly transformed\n",
    "    remainder='passthrough' # Keep other columns (if any) - though not applicable here\n",
    ")\n",
    "\n",
    "preprocessor_y = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('t_y', StandardScaler(), y_num_col)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Apply transformations using fit_transform on training data and transform on\n",
    "# testing one\n",
    "X_train_processed = preprocessor_X.fit_transform(X_train)\n",
    "X_test_processed = preprocessor_X.transform(X_test)\n",
    "\n",
    "y_train_log_df = y_train_log.to_frame()\n",
    "\n",
    "#y_train_processed = preprocessor_y.fit_transform(y_train_log_df)\n",
    "#y_test_processed = preprocessor_y.transform(y_test_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e5d5c912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando os folds para a validação cruzada\n",
    "num_particoes = 10 # número de folds da validação cruzada\n",
    "kfold = KFold(n_splits=num_particoes, shuffle=True, random_state=7) # faz o particionamento em 10 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f45110c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelagem\n",
    "\n",
    "SEED = 7\n",
    "# Definindo uma seed global para esta célula de código\n",
    "np.random.seed(SEED) \n",
    "random.seed(SEED)\n",
    "\n",
    "# Listas para armazenar os modelos, os resultados e os nomes dos modelos\n",
    "models = []\n",
    "results = []\n",
    "names = []\n",
    "\n",
    "# Preparando os modelos e adicionando-os em uma lista\n",
    "models.append(('Dummy',  DummyRegressor(strategy='median')))\n",
    "models.append(('LR', LinearRegression()))\n",
    "models.append(('Ridge', Ridge()))\n",
    "models.append(('Lasso', Lasso()))\n",
    "models.append(('KNN', KNeighborsRegressor()))\n",
    "models.append(('CART', DecisionTreeRegressor()))\n",
    "models.append(('RFR', RandomForestRegressor(random_state=SEED)))\n",
    "models.append(('SVM', SVR()))\n",
    "\n",
    "# Avaliando um modelo por vez\n",
    "for name, model in models:\n",
    "  cv_results = cross_val_score(model, X_train_processed, y_train_processed, cv=kfold, scoring='neg_mean_squared_error')\n",
    "  results.append(cv_results)\n",
    "  names.append(name)\n",
    "  # imprime MSE, desvio padrão do MSE e RMSE dos 10 resultados da validação cruzada\n",
    "  msg = \"%s: MSE %0.2f (%0.2f) - RMSE %0.2f\" % (name, abs(cv_results.mean()), cv_results.std(), np.sqrt(abs(cv_results.mean())))\n",
    "  print(msg)\n",
    "\n",
    "# Boxplot de comparação dos modelos\n",
    "#fig = plt.figure() \n",
    "#fig.suptitle('Comparação do MSE dos Modelos') \n",
    "#ax = fig.add_subplot(111) \n",
    "#plt.boxplot(results) \n",
    "#ax.set_xticklabels(names) \n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a8623a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "SEED = 7\n",
    "# Definindo uma seed global para esta célula de código\n",
    "np.random.seed(SEED) \n",
    "random.seed(SEED)\n",
    "#\n",
    "# RMSE in real price space\n",
    "def rmse_real(y_true_log, y_pred_log):\n",
    "    y_true = np.expm1(y_true_log)   # invert log1p\n",
    "    y_pred = np.expm1(y_pred_log)\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "\n",
    "# MAE in real price space\n",
    "def mae_real(y_true_log, y_pred_log):\n",
    "    y_true = np.expm1(y_true_log)\n",
    "    y_pred = np.expm1(y_pred_log)\n",
    "    return mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "\n",
    "def evaluate_model(model, X, y_log, cv):\n",
    "    \"\"\"\n",
    "    Evaluate a regression model trained on log(price).\n",
    "    \n",
    "    Returns a dictionary with:\n",
    "    - log-RMSE\n",
    "    - real-RMSE\n",
    "    - real-MAE\n",
    "    \"\"\"\n",
    "    \n",
    "    # Log RMSE\n",
    "    scores_log = cross_val_score(\n",
    "        model, X, y_log, cv=cv, scoring=\"neg_mean_squared_error\"\n",
    "    )\n",
    "    log_rmse = -scores_log.mean()\n",
    "    \n",
    "    # Real RMSE\n",
    "    scores_real_rmse = cross_val_score(\n",
    "        model, X, y_log, cv=cv, scoring=rmse_real_scorer\n",
    "    )\n",
    "    real_rmse = -scores_real_rmse.mean()\n",
    "    \n",
    "    # Real MAE\n",
    "    scores_real_mae = cross_val_score(\n",
    "        model, X, y_log, cv=cv, scoring=mae_real_scorer\n",
    "    )\n",
    "    real_mae = -scores_real_mae.mean()\n",
    "    \n",
    "    return {\n",
    "        \"Log RMSE\": log_rmse,\n",
    "        \"Real RMSE\": real_rmse,\n",
    "        \"Real MAE\": real_mae\n",
    "    }\n",
    "\n",
    "rmse_real_scorer = make_scorer(rmse_real, greater_is_better=False)\n",
    "mae_real_scorer = make_scorer(mae_real, greater_is_better=False)\n",
    "\n",
    "models = {\n",
    "    \"Dummy Regresssor\": DummyRegressor(strategy='median'),\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Ridge\": Ridge(),\n",
    "    \"Lasso\": Lasso(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(),\n",
    "    \"Random Forest\": RandomForestRegressor(random_state=SEED),\n",
    "    \"KNN\": KNeighborsRegressor(),\n",
    "    \"SVM\": SVR()\n",
    "}\n",
    "\n",
    "#model = SVR(kernel=\"rbf\")\n",
    "#model = DummyRegressor(strategy='median')\n",
    "#model = LinearRegression()\n",
    "# Criando os folds para a validação cruzada\n",
    "num_particoes = 10 # número de folds da validação cruzada\n",
    "kfold = KFold(n_splits=num_particoes, shuffle=True, random_state=7) # faz o particionamento em 10 folds\n",
    "\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    results[name] = evaluate_model(model, X_train_processed, y_train_log_df, cv=kfold)\n",
    "\n",
    "df_results = pd.DataFrame(results).T  # transpose for readability\n",
    "print(df_results)\n",
    "\n",
    "\n",
    "#results = evaluate_model(model, X_train_processed, y_train_log_df, cv=kfold)\n",
    "#print(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "bd166b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X, y_log, cv):\n",
    "    \"\"\"\n",
    "    Evaluate a regression model trained on log(price).\n",
    "    \n",
    "    Returns a dictionary with:\n",
    "    - log-RMSE\n",
    "    - real-RMSE\n",
    "    - real-MAE\n",
    "    \"\"\"\n",
    "    \n",
    "    # Log RMSE\n",
    "    scores_log = cross_val_score(\n",
    "        model, X, y_log, cv=cv, scoring=\"neg_mean_squared_error\"\n",
    "    )\n",
    "    log_rmse = -scores_log.mean()\n",
    "    \n",
    "    # Real RMSE\n",
    "    scores_real_rmse = cross_val_score(\n",
    "        model, X, y_log, cv=cv, scoring=rmse_real_scorer\n",
    "    )\n",
    "    real_rmse = -scores_real_rmse.mean()\n",
    "    \n",
    "    # Real MAE\n",
    "    scores_real_mae = cross_val_score(\n",
    "        model, X, y_log, cv=cv, scoring=mae_real_scorer\n",
    "    )\n",
    "    real_mae = -scores_real_mae.mean()\n",
    "    \n",
    "    return {\n",
    "        \"Log RMSE\": log_rmse,\n",
    "        \"Real RMSE\": real_rmse,\n",
    "        \"Real MAE\": real_mae\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "03156693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Optimizing Linear Regression...\n",
      "🔍 Optimizing Ridge...\n",
      "🔍 Optimizing Lasso...\n",
      "🔍 Optimizing Decision Tree...\n",
      "🔍 Optimizing KNN...\n",
      "🔍 Optimizing SVM...\n",
      "🔍 Optimizing Random Forest...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Log RMSE</th>\n",
       "      <th>Real RMSE</th>\n",
       "      <th>Real MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>0.02</td>\n",
       "      <td>848.83</td>\n",
       "      <td>405.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.02</td>\n",
       "      <td>904.45</td>\n",
       "      <td>415.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>0.07</td>\n",
       "      <td>1,875.54</td>\n",
       "      <td>920.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.04</td>\n",
       "      <td>1,278.34</td>\n",
       "      <td>634.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.04</td>\n",
       "      <td>1,221.93</td>\n",
       "      <td>622.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.02</td>\n",
       "      <td>875.24</td>\n",
       "      <td>411.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.03</td>\n",
       "      <td>1,110.56</td>\n",
       "      <td>540.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Log RMSE  Real RMSE  Real MAE\n",
       "Linear Regression      0.02     848.83    405.86\n",
       "Ridge                  0.02     904.45    415.54\n",
       "Lasso                  0.07   1,875.54    920.94\n",
       "Decision Tree          0.04   1,278.34    634.45\n",
       "KNN                    0.04   1,221.93    622.99\n",
       "SVM                    0.02     875.24    411.37\n",
       "Random Forest          0.03   1,110.56    540.40"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "base_models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Ridge\": Ridge(),\n",
    "    \"Lasso\": Lasso(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(),\n",
    "    \"KNN\": KNeighborsRegressor(),\n",
    "    \"Random Forest\": RandomForestRegressor(random_state=42),\n",
    "    \"SVM\": SVR(),\n",
    "}\n",
    "\n",
    "\n",
    "# Define parameter spaces\n",
    "# prepare reasonable search spaces for each model\n",
    "\n",
    "param_spaces = {\n",
    "    \"Linear Regression\": {},  # no hyperparameters to tune\n",
    "    \"Ridge\": {\n",
    "        \"alpha\": np.logspace(-3, 3, 50)\n",
    "    },\n",
    "    \"Lasso\": {\n",
    "        \"alpha\": np.logspace(-3, 3, 50)\n",
    "    },\n",
    "    \"Decision Tree\": {\n",
    "        \"max_depth\": [3, 5, 10, None],\n",
    "        \"min_samples_split\": [2, 5, 10, 20],\n",
    "        \"min_samples_leaf\": [1, 2, 5, 10]\n",
    "    },\n",
    "    \"KNN\": {\n",
    "        \"n_neighbors\": range(2, 50),\n",
    "        \"weights\": [\"uniform\", \"distance\"],\n",
    "        \"p\": [1, 2]  # Manhattan / Euclidean\n",
    "    },\n",
    "    \"SVM\": {\n",
    "        \"C\": np.logspace(-2, 3, 20),\n",
    "        \"gamma\": np.logspace(-3, 2, 20),\n",
    "        \"kernel\": [\"rbf\", \"poly\", \"sigmoid\"]\n",
    "    },\n",
    "    \"Random Forest\": {\n",
    "        \"n_estimators\": [100, 200, 300, 500],\n",
    "        \"max_depth\": [None, 5, 10, 20],\n",
    "        \"min_samples_split\": [2, 5, 10],\n",
    "        \"min_samples_leaf\": [1, 2, 4],\n",
    "        \"max_features\": [\"auto\", \"sqrt\", \"log2\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "num_particoes = 10 # número de folds da validação cruzada\n",
    "kfold = KFold(n_splits=num_particoes, shuffle=True, random_state=7) # faz o particionamento em 10 folds\n",
    "\n",
    "searches = {}\n",
    "for name, model in base_models.items():\n",
    "    if param_spaces[name]:  # if we have params to tune\n",
    "        searches[name] = RandomizedSearchCV(\n",
    "            estimator=model,\n",
    "            param_distributions=param_spaces[name],\n",
    "            n_iter=10,   # number of random trials\n",
    "            scoring=\"neg_root_mean_squared_error\",\n",
    "            cv=3, #kfold,        # inner CV for hyperparameter tuning\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "    else:\n",
    "        searches[name] = model  # LinearRegression (no hyperparams)\n",
    "\n",
    "results = {}\n",
    "for name, search in searches.items():\n",
    "    print(f\"🔍 Optimizing {name}...\")\n",
    "    results[name] = evaluate_model(search, X_train_processed, y_train_log_df, cv=3) #kfold)  # outer CV\n",
    "\n",
    "pd.set_option(\"display.float_format\", \"{:,.2f}\".format)\n",
    "df_results = pd.DataFrame(results).T\n",
    "#df_results.style.format(\"{:,.2f}\")\n",
    "df_results\n",
    "#print(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fd98a4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score 0.97\n",
      "MSE 0.03\n",
      "RMSE 0.18\n",
      "\n",
      "Real MAE 34798.83\n",
      "Real MSE 12742045481149.05\n",
      "Real RMSE 3569600.19\n",
      "R² -800556.73\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train_processed, y_train_log_df)\n",
    "pred_log = model.predict(X_test_processed)\n",
    "score = model.score(X_test_processed, y_test_log)\n",
    "print(\"score %0.2f\" % score)\n",
    "\n",
    "mse = mean_squared_error(y_test_log, pred_log)\n",
    "print(\"MSE %0.2f\" % mse)\n",
    "print(\"RMSE %0.2f\" % np.sqrt(abs(mse))) \n",
    "print(\"\")\n",
    "y_true = np.expm1(y_test_log)   # invert log1p\n",
    "y_pred = np.expm1(pred_log)\n",
    "r_mae = mean_absolute_error(y_true, y_pred)\n",
    "r_mse = mean_squared_error(y_true, y_pred)\n",
    "r_rmse = np.sqrt(r_mse)\n",
    "print(\"Real MAE %0.2f\" % r_mae)\n",
    "print(\"Real MSE %0.2f\" % r_mse)\n",
    "print(\"Real RMSE %0.2f\" % r_rmse)\n",
    "print(\"R² %0.2f\" % r2_score(y_true, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
